{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Companion Guide Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(r\"C://Users//Melton//OneDrive//Documents//Afya//HPSJ//274CompanionGuideParsed.xlsx\", engine = \"openpyxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Loop\\xa0\\xa0', 'Reference\\xa0', 'Name\\xa0', 'Codes\\xa0',\n",
       "       'Notes/Comments'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 0.0, 'ZZ', 'ZZ\\xa0', 'DHCS-PROV NETWK', '^', 405.0, 0.0, ':', 'PW', 'DHCS-PROV NETWK', '004050X109', 274.0, '004050X109\\xa0', 28.0, 27.0, 'ACV', 'FI', 'NN', 40.0, 'DHCS\\xa0\\xa0', 'Managed\\xa0\\xa0', 'Care', 'QV', 'XX\\xa0', '092, 093\\xa0', 68.0, 77.0, 'XX', 'AJ\\xa0', 'TE\\xa0', 'EM\\xa0', 'FX\\xa0', 'ENG\\xa0', 'A, B, C\\xa0 or D', '092,\\xa0\\xa0', 93.0, 'C4\\xa0', 'P7, P8\\xa0', 'DJ', '1R, 1S,\\xa0 1T, 1U,\\xa0 1V, 1Y,\\xa0 2E, 2S', 'F, M', 77.0, 68.0, '3E, 3G\\xa0', 'N5', 30.0, 2.0, 'EQ\\xa0', '1P\\xa0', 'XX', 'ENG\\xa0', 4.0, 'A, B,\\xa0\\xa0', 'C or D', '092,\\xa0\\xa0', 93.0, 68.0, '3E, 3G\\xa0', 'YR\\xa0', 'Y\\xa0', 'N5']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "_codes = df['Codes\\xa0'].to_numpy().tolist()\n",
    "codes = []\n",
    "\n",
    "for i in df['Codes\\xa0'].to_numpy().tolist():\n",
    "    try:\n",
    "        v = (float(i))\n",
    "        if not (math.isnan(v)):\n",
    "            codes.append(v)\n",
    "    except:\n",
    "        codes.append(i)\n",
    "        pass\n",
    "        \n",
    "print(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_names = df['Name\\xa0'].to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ISA01 ', 'ISA02 ', 'ISA03 ', 'ISA04 ', 'ISA05 ', 'ISA06 ', 'ISA07 ', 'ISA08 ', 'ISA11 ', 'ISA12 ', 'ISA13 ', 'ISA14 ', 'ISA16 ', 'IEA02 ', 'GS01 ', 'GS02 ', 'GS03 ', 'GS06 ', 'GS08 ', 'GE02 ', 'ST01 ', 'ST02 ', 'ST03 ', 'SE01 ', 'SE02 ', 'BHT ', 'BHT01 ', 'BHT02 ', 'BHT03 ', 'BHT04 ', 'BHT05 ', 'NM1 ', 'NM101 ', 'NM103 ', 'NM108 ', 'NM109 ', 'NM1 ', 'NM101 ', 'NM103 ', 'NM1 ', 'NM101 ', 'NM103 ', 'NM1 ', 'NM101 ', 'NM103 ', 'NM108 ', 'NM109 ', 'N2 ', 'N201 ', 'DTP ', 'DTP01 ', 'DTP03 ', 'LQ ', 'LQ01 ', 'LQ02 ', 'TPB ', 'REF ', 'NM1 ', 'N2 ', 'NM1 ', 'NM101 ', 'NM103 ', 'NM108 ', 'NM109 ', 'N2 ', 'N201 ', 'N202 ', 'PER ', 'PER01 ', 'PER03 ', 'PER04 ', 'PER05 ', 'PER06 ', 'PER07 ', 'PER08 ', 'LUI ', 'LUI02 ', 'LUI05 ', 'LUI ', 'LUI02 ', 'LUI05 ', 'DTP ', 'DTP01 ', 'DTP03 ', 'WS ', 'WS01 ', 'WS02 ', 'WS03 ', 'CRC ', 'CRC01 ', 'CRC03 ', 'CRC ', 'CRC01 ', 'CRC03, ', 'CRC04, ', 'CRC05, ', 'CRC06, ', 'CRC07', 'PDI ', 'PDI01 ', 'PDI02 ', 'PDI03 ', 'NX1 ', 'NX101 ', 'N3 ', 'N301 ', 'N302 ', 'N4 ', 'N401 ', 'N402 ', 'N403 ', 'LQ ', 'LQ01 ', 'LQ02 ', 'TPB ', 'TPB01 ', 'REF ', 'REF01 ', 'REF02 ', 'NM1 ', 'NM101 ', 'NM102 ', 'NM103 ', 'NM108 ', 'NM109 ', 'N2 ', 'N201 ', 'NM1 ', 'NM101 ', 'NM103 ', 'NM104 ', 'NM105 ', 'NM107 ', 'NM108 ', 'NM109 ', 'N2 ', 'N201 ', 'N202 ', 'N2 ', 'N201 ', 'N2 ', 'N201 ', 'N202 ', 'DEG ', 'DEG01 ', 'DEG04 ', 'LUI ', 'LUI02 ', 'LUI05 ', 'LUI ', 'LUI02 ', 'LUI05 ', 'DTP ', 'DTP01 ', 'DTP03 ', 'LQ ', 'LQ01 ', 'LQ02 ', 'TPB ', 'TPB01 ', 'YNQ ', 'YNQ01 ', 'YNQ02 ', 'REF ', 'REF01 ', 'REF02 ']\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "_references = df['Reference\\xa0'].to_numpy().tolist()\n",
    "references = []\n",
    "\n",
    "for i in df['Reference\\xa0'].to_numpy().tolist():\n",
    "    try:\n",
    "        v = (float(i))\n",
    "        if not (math.isnan(v)):\n",
    "            references.append(unicodedata.normalize(\"NFKD\", v))\n",
    "    except:\n",
    "        references.append(unicodedata.normalize(\"NFKD\", i))\n",
    "        pass\n",
    "        \n",
    "print(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "for i,r in enumerate(_references):\n",
    "    try:\n",
    "        # Usually, v will be nan, but what if not?\n",
    "        v = float(r)\n",
    "    except:\n",
    "        # If v is a string, begin collecting \"names\"\n",
    "        t_name = _names[new_i]\n",
    "        new_i = i+1\n",
    "        while(True):\n",
    "            n = _names[new_i]\n",
    "            try:\n",
    "                # Usually, _v will be nan as well\n",
    "                # If it is nan, leave loop and save the full\n",
    "                # name of the header\n",
    "                _v = float(n)\n",
    "                if(math.isnan(_v)):\n",
    "                    names.append(t_name)\n",
    "                    break\n",
    "            except:\n",
    "                # Only combine if _references at the same\n",
    "                # index is also a nan else, break\n",
    "                __v = _references[new_i]\n",
    "                try:\n",
    "                    _r = float(__v)\n",
    "                    if(math.isnan(_r)):\n",
    "                        t_name = t_name + ' ' + n\n",
    "                        new_i += 1\n",
    "                except:\n",
    "                    names.append(t_name)\n",
    "                    break\n",
    "\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NM1  Information  Source   Name\n"
     ]
    }
   ],
   "source": [
    "print(references[31],names[31])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input File Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = []\n",
    "\n",
    "with open(r\"C://Users//Melton//OneDrive//Documents//Afya//HPSJ//Data_readable.txt\",'r') as f:\n",
    "    temp = f.read()\n",
    "    [input_file.append(t) for t in temp.split('\\n')]\n",
    "    \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
